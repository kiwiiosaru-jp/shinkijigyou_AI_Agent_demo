
# 保全業務DXおよび既存データ資産化プロジェクト 提案書（Markdown版）

## 目次

1. タイトル
2. 本日のアジェンダ
3. プロジェクト背景（弊社理解）
4. ご提案サマリ（3つの柱）
5. 現状の課題：負の連鎖（Vicious Cycle）
6. 技術アプローチの全体像（LLM主導）
7. 提案要旨①の深掘り：AIクレンジング＆マスタ自動生成
8. アルゴリズム詳細（ラインマスタ：文字列距離＋LLM）
9. アルゴリズム詳細（設備・部品マスタ：LLM＋Embedding）
10. アルゴリズム詳細（分類・標準用語辞書）
11. 提案要旨②の深掘り：RAG検索＆AI入力支援アプリ
12. 提案要旨③の深掘り：少し試す→確かめる→全体に広げる と “育てる”運用
13. 「育てる」① 初期構築でマスタを育てる（10％ → 90％）
14. 「育てる」② 運用しながらマスタを育てる
15. 「育てる」③ 保全報告データを運用の中で育てる
16. システムアーキテクチャ
17. Power Platform ライセンス選択ガイド
18. プロジェクトロードマップ（3ヶ月）
19. 概算費用とROI
20. 将来の発展イメージ（本スコープ外：予防保全）
21. 次のアクション（Next Steps）
22. 体制とDATUM STUDIOの強み

---

## 1. タイトル

**タイトル**  
保全業務DXおよび既存データ資産化プロジェクトのご提案  

**サブタイトル**  
Power Platform × Generative AI (GPT-5) による「ナレッジ駆動型保全」への変革  

**宛名**  
いすゞ自動車株式会社 御中  

**日付**  
2026年1月  

**提案者**  
DATUM STUDIO  

---

## 2. 本日のアジェンダ

1. プロジェクト背景とご提案サマリ  
2. 現状の課題：「負の連鎖」と23万件データの状況  
3. 技術アプローチの全体像（LLM主導）  
4. 提案要旨①：AIクレンジング＆マスタ自動生成  
5. 提案要旨②：RAG検索＆AI入力支援アプリ  
6. 提案要旨③：  
   「少し試す → 確かめる → 全体に広げる」と  
   マスタ／保全データを“育てる”運用  
7. システムアーキテクチャ  
8. Power Platform ライセンスとロードマップ  
9. 概算費用とROI  
10. 将来の発展イメージ（本スコープ外：予防保全）  
11. 次のアクション／体制と実績  

---

## 3. プロジェクト背景（弊社理解）

### ヘッダーメッセージ

> 「23万件の埋蔵データの資産化」と「現場入力業務の高度化」の課題に対し、Azure OpenAI × Power Platformによる保全ナレッジDX基盤の構築をご提案いたします。  
> 生成AIによるデータクレンジングの自動化と、検索・入力支援アプリの実装を通じて、現場の負荷を増やさずに高品質な保全データを継続的に蓄積できる仕組みを実現します。

### 貴社の現状（弊社理解）

- 既存の**保全履歴23万件**は、すでにCSV/DBとして **構造化されている**。  
- しかし、  
  - 表記揺れ（例：モータ／モーター／Mtr）  
  - 略語・誤字  
  - 項目のズレ（原因欄に処置内容が入っている 等）  
  により、**そのままでは信頼して検索・分析に使えない**。  
- 人手で全件修正すると、  
  - 23万件 × 5分/件 = 約19,000時間  
  - 現場では実質的に対応不可能。  

### 負の連鎖の構造

- 過去事例が検索でヒットしない → 毎回ゼロから調査・復旧。  
- 入力ルールも徹底しきれず、**新たな揺らぎデータが毎日増える**。  
- 時間が経つほど、「データ量は増えるが、活用難易度だけ上がる」状態に。  

---

## 4. ご提案サマリ（3つの柱）

### 提案要旨①：AIクレンジング＆マスタ自動生成による「23万件の一括資産化」

- GPT-5による構造化・補正エンジンと、  
  Embedding＋クラスタリングによる名寄せロジックにより、  
  既存23万件データを自動クレンジング。  
- 設備・現象・原因・処置マスタ＋標準用語辞書を自動生成。  
- 約19,000時間相当の人手作業をAIで代替。  

### 提案要旨②：RAG検索＆AI入力支援アプリによる「勝手に整うデータ運用」

- Power Apps上に、Azure OpenAIと連携した検索・入力支援アプリを構築。  
- 現場は「自然な日本語で入力するだけ」。  
  → 過去類似事例の提示・標準用語への変換・構造化補完が自動で実行。  
- **「現場が楽になればなるほど、データが勝手に整っていく」**サイクルを実現。  

### 提案要旨③：  
### 「少し試す → 確かめる → 全体に広げる」と  
### マスタ／保全データを少しずつ“育てる”運用設計

- いきなり全件自動ではなく、まず**約10％のサンプルでAIがマスタのたたき台を作成**。  
- 人が確認したうえで、残りの90％に一括適用し、処理中に見つかる「新しい設備・事象」をマスタに追加。  
- 運用開始後も、  
  - 新しい設備・事象が出てきたらアプリからマスタに追加。  
  - 初期クレンジングで埋めきれなかった項目は「要確認」として残し、  
    類似案件検索のタイミングで現場が**“ついでに補正”**できる。  
- これにより、**マスタ（用語集）と保全報告データの両方を、運用の中で育てていく**。  

---

## 5. 現状の課題：負の連鎖（Vicious Cycle）

### 顧客の真のペイン

> 「データを使って業務を効率化したいが、検索しても過去の類似事象がヒットしない。  
>  結果として入力の手間も減らず、ナレッジも活用できない。」

### 負の連鎖のメカニズム

1. 過去データに表記揺れ・項目ズレ・欠損が多く、検索してもヒットしない。  
2. データを直したいが、現場にその工数（約19,000時間）は確保できない。  
3. 既存の揺らぎデータは放置され、日々の入力で新たな揺らぎが再生産。  
4. 時間が経つほど、データ量は増えるが活用困難さは増していく。  

### ブレークスルー

- 現場が確保できない「約19,000時間」の工数を、  
  AI（GPT-5）という**仮想労働力**で肩代わりし、  
  このループを断ち切る。  

---

## 6. 技術アプローチの全体像（LLM主導）

### 基本コンセプト

- MeCab/Sudachiなどの従来の形態素解析ではなく、  
  **GPT-5による文脈理解＋構造化（JSON出力）を中核**に据えた設計。  
- そのうえで、Embedding＋クラスタリングで  
  - 設備／部品  
  - 現象／原因／処置  
  のマスタと標準用語辞書をボトムアップに自動生成。  

### 全体処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(23万件)
    participant ETL as バッチETL
    participant LLM as GPT-5(構造化)
    participant EMB as Embedding/クラスタ
    participant MAST as マスタDB/辞書
    participant CLEAN as クレンジング処理

    DB->>ETL: 保全レコードを取得
    loop 各レコード
        ETL->>LLM: 元テキストと既存項目を送信
        LLM-->>ETL: 構造化JSONを返却
        ETL->>EMB: 抽出された用語を登録
    end
    EMB-->>MAST: クラスタごとのマスタ候補を出力
    LLM->>MAST: 候補をもとに代表名を決定
    MAST-->>CLEAN: 確定マスタと標準辞書を提供
    CLEAN->>DB: 既存23万件をマスタ参照で補正・更新
```

---

## 7. 提案要旨①の深掘り：AIクレンジング＆マスタ自動生成

### 目的

- 既存の23万件の構造化データについて、  
  - 項目ズレ（原因欄に処置等）を正しい欄に入れ直す。  
  - 表記揺れ・略語・誤字を標準用語に揃える。  
  - 空欄を文脈から可能な範囲で補完する。  
- その結果として、  
  - 設備マスタ  
  - 現象／原因／処置の分類マスタ  
  - 標準用語辞書（variantとcanonicalの対応）  
  を自動生成・整備する。  

### クレンジング後にできること

- 類似案件検索で、  
  - 「設備」「現象」「原因」「処置」を軸に検索可能。  
- 統計分析・傾向分析の精度が向上。  
- 以後の入力支援・RAG検索の“土台データ”として活用。  

### 詳細フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant Batch as クレンジングバッチ
    participant LLM as GPT-5(構造化と補正案)
    participant EMB as Embedding/クラスタ
    participant MAST as マスタ管理
    participant OUT as クレンジング済DB

    DB->>Batch: レコード一覧を取得
    loop 各レコード
        Batch->>LLM: レコード内容を送信
        LLM-->>Batch: 構造化結果と補正案を返却
        Batch->>EMB: 抽出用語をクラスタ用に登録
    end
    EMB->>LLM: クラスタごとの用語リストを送信
    LLM-->>MAST: 各クラスタの代表名と分類を提案
    MAST-->>Batch: 確定マスタと標準辞書を提供
    loop 各レコード
        Batch->>Batch: マスタ・辞書を参照して補正
        Batch->>OUT: クレンジング済レコードを書き込み
    end
```

---

## 8. アルゴリズム詳細：ラインマスタ（文字列距離＋LLM）

### 目的

- 「Aライン」「A-Line」「Line A」などの揺らぎを名寄せし、  
  **ラインを一意に識別**できるようにする。  

### 考え方

- ライン名は意味よりも**記号的な違い**が重要。  
- Embeddingだけに頼ると、A/Bラインが「同じ工場のライン」として近くなり過ぎるリスク。  
- そのため、  
  - 文字列正規化（全角/半角・記号・大小文字）  
  - Levenshtein距離でのグルーピング  
  - 最後にLLMで正式名称決定  
  というハイブリッド方式を採用。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(ライン情報)
    participant LineETL as ライン名抽出処理
    participant Norm as 文字列正規化
    participant Cls as 距離ベースクラスタ
    participant LLM as GPT-5(正式名称決定)
    participant MLine as ラインマスタ/辞書

    DB->>LineETL: ライン名候補を抽出
    LineETL->>Norm: ライン文字列を正規化
    Norm-->>Cls: 正規化済みライン名一覧
    Cls->>Cls: 距離計算とクラスタリングを実行
    loop 各クラスタ
        Cls->>LLM: クラスタ内候補と文脈情報を送信
        LLM-->>Cls: 正式名称と別名リストを返却
        Cls->>MLine: ラインマスタに登録
        MLine->>MLine: 別名から正式名称への辞書を更新
    end
```

---

## 9. アルゴリズム詳細：設備・部品マスタ（LLM＋Embedding）

### 目的

- 文章や項目の中に埋もれている  
  「設備」「部品」を抽出し、  
  - 設備マスタ  
  - 部品マスタ  
  - 設備＞部品の親子関係  
  を構造化する。  

### ポイント

- GPT-5が  
  - line（ライン）  
  - equipment（設備）  
  - part（部品）  
  などを文脈から抽出。  
- 抽出された用語をEmbeddingし、クラスタリングで名寄せ。  
- GPT-5で、クラスタごとの代表名（標準設備名）と親子関係を決定。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant ETL as 設備候補抽出
    participant LLM as GPT-5(設備と部品抽出)
    participant EMB as Embedding/クラスタ
    participant MEquip as 設備/部品マスタDB

    DB->>ETL: レコードを取得
    loop 各レコード
        ETL->>LLM: テキストと既存設備名を送信
        LLM-->>ETL: 抽出結果をJSONで返却
        ETL->>EMB: equipmentとpartをクラスタ用に登録
    end
    EMB->>LLM: 用語クラスタ一覧を送信
    LLM-->>MEquip: 標準設備名・標準部品名・親子関係を決定
    MEquip->>MEquip: 設備マスタ・部品マスタ・別名辞書を更新
```

---

## 10. アルゴリズム詳細：分類・標準用語辞書

### 目的

- 現象・原因・処置を、  
  - 大分類  
  - 中分類  
  - 小分類  
  の階層に整理（Taxonomy）。  
- 略語・俗語を含む表記揺れを、標準用語辞書に集約。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as クレンジング候補DB
    participant ETL as テキスト抽出
    participant LLM as GPT-5(現象/原因/処置抽出)
    participant EMB as Embedding/クラスタ
    participant MClass as 分類マスタ
    participant Dict as 標準用語辞書

    DB->>ETL: 現象と原因と処置を取得
    loop 各レコード
        ETL->>LLM: テキストを送信
        LLM-->>ETL: 現象/原因/処置を抽出
        ETL->>EMB: 用語をEmbedding登録
    end
    EMB->>LLM: クラスタごとの用語リストを送信
    LLM-->>MClass: 大中小分類のラベル案を生成
    LLM-->>Dict: 標準用語と別名の対応表を生成
    MClass->>MClass: 分類マスタを更新
    Dict->>Dict: 標準用語辞書を更新
```

---

## 11. 提案要旨②の深掘り：RAG検索＆AI入力支援アプリ

### コンセプト

> 「現場が自由に入力するだけで、裏でAIが標準化と構造化を代行する」

### 主な機能

1. **RAGによる類似案件提示**  
2. **インテリジェント入力支援（標準用語化・構造化・不足項目の補完）**  
3. **「要確認」データの自然な解消**  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps(保全アプリ)
    participant Flow as Power Automate
    participant Func as Azure Functions(API)
    participant LLM as GPT-5(構造化と提案)
    participant Search as Azure AI Search
    participant DV as Dataverse(保全DBとマスタと辞書)

    User->>App: 現象や対応内容を入力
    App->>Flow: 入力テキストを送信
    Flow->>Func: APIリクエストを送信
    Func->>LLM: 入力テキストとマスタ/辞書を渡す
    LLM-->>Func: 構造化結果と標準用語候補と不足項目を返却
    Func->>Search: 類似案件検索を実行
    Search-->>Func: 類似事例一覧を返却
    Func-->>App: 類似事例と標準用語案と不足項目の質問を返却
    App-->>User: 変換案や確認メッセージを表示
    User->>App: 承認や修正を入力
    App->>Flow: 確定データを送信
    Flow->>DV: 保全DBやマスタや辞書を更新
```

---

## 12. 提案要旨③の深掘り：  
## 「少し試す → 確かめる → 全体に広げる」と  
## マスタ／保全データを“育てる”運用

### 3つの「育てる」

1. **初期構築でマスタを育てる（10％ → 90％）**  
2. **運用しながらマスタを育てる（新しい設備・事象への対応）**  
3. **運用しながら保全報告データを育てる（埋まっていない項目を“ついでに”補正）**  

---

## 13. 「育てる」① 初期構築でマスタを育てる（10％ → 90％）

### ステップ1：データの約10％で「たたき台」を作る

- 23万件のうち、ライン・設備・年度のバランスを見ながら約10％を抽出。  
- GPT-5で構造化し、設備／現象／原因／処置マスタの**たたき台**を自動生成。  

### ステップ2：たたき台だけ人がチェックする

- 10％分から作られたマスタ候補を、担当者がざっと確認。  
- 全23万件を見るのではなく、**代表例だけを見るので負荷が小さい**。  

### ステップ3：残り90％に広げながら、未知のものをマスタに追加

- 検証済みマスタを「正解」として、残り90％を一括処理。  
- 処理中に、既存マスタに当てはまらない新しい設備・事象が出てきたら、  
  AIが「マスタ追加候補」として自動登録。  
- 後から「マスタ追加候補」一覧を人が見て、採用／不採用を決めることで、  
  **マスタが一段階レベルアップ**していく。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(23万件)
    participant Sampler as サンプル抽出(約10%)
    participant LLM as GPT-5(構造化)
    participant EMB as Embedding/クラスタ
    participant Reviewer as 担当者
    participant MAST as マスタDB
    participant Batch as 全体バッチ処理

    DB->>Sampler: 全データを渡す
    Sampler-->>LLM: 約10%サンプルを送信
    loop サンプルデータ
        LLM-->>EMB: 抽出した用語を登録
    end
    EMB->>LLM: クラスタ情報を渡す
    LLM-->>MAST: マスタ骨子案を生成
    Reviewer->>MAST: 骨子案を確認して修正
    MAST->>Batch: 確定マスタを提供
    Batch->>DB: 残り90%を読み込み
    loop 各レコード
        Batch->>LLM: レコードと確定マスタを送信
        LLM-->>Batch: マッチング結果と未知候補を返却
        alt 既存マスタにマッチ
            Batch->>DB: クレンジング済として更新
        else 未知候補
            Batch->>MAST: マスタ追加候補として登録
        end
    end
```

---

## 14. 「育てる」② 運用しながらマスタを育てる

### 状況

- 新しい設備が導入された。  
- これまで起きていなかった新種の現象が発生した。  

### 流れ

1. 現場がアプリ上で新しい設備・現象を入力。  
2. GPT-5が既存マスタと似ているかを判定。  
3. どれにも当てはまらなければ、  
   - 「新しい設備として登録しますか？」  
   - 「新しい現象分類として追加しますか？」  
   と提案。  
4. 承認されると、その場でマスタに反映。  
   - 以後は同じ表現が出てきても、自動で同じマスタIDに紐づく。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant MAST as マスタDB

    User->>App: 新しい設備や現象を含む報告を入力
    App->>Func: 入力内容を送信
    Func->>LLM: 入力内容と既存マスタを送信
    LLM-->>Func: 類似マスタ候補と類似度とコメントを返却
    alt 類似度が高い場合
        Func-->>App: 既存マスタとの紐づけ案を表示
        User->>App: 案を承認
        App->>MAST: 既存マスタIDへの紐づけを登録
    else 新規マスタが妥当な場合
        Func-->>App: 新しいマスタとして登録するか確認
        User->>App: 登録を承認
        App->>MAST: 新しい設備や現象マスタを登録
    end
```

---

## 15. 「育てる」③ 保全報告データを運用の中で育てる

### 前提

- 初期クレンジングの段階で、  
  GPT-5のconfidenceが低い項目は無理に埋めず、  
  - フィールドは空欄のまま。  
  - 「要確認」フラグをON。  
  としてナレッジDBに登録。  

### 日常運用の中での「ついでに補正」

1. 現場が類似案件を検索し、検索結果一覧から案件を開く。  
2. 開いた案件が「要確認」フラグ付きの場合、  
   - 「この案件は原因が未入力です。わかる範囲で補足しますか？」  
     と小さなメッセージを表示。  
3. 担当者が余裕のある範囲で、1〜2項目だけ補足入力。  
4. GPT-5が入力内容をチェックし、  
   - 保全報告データに反映。  
   - 必要に応じてマスタ／辞書にも反映。  
5. 以後、その案件は**「要確認」から「確定済」へ昇格**。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps
    participant Search as Azure AI Search
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant DV as Dataverse(保全DB)

    User->>App: 類似案件を検索
    App->>Search: 検索クエリを送信
    Search-->>App: 検索結果を返却
    User->>App: 要確認案件を選択
    App->>DV: 案件詳細を取得
    alt 要確認フラグがある場合
        App-->>User: 「原因が未入力です。補足しますか？」と表示
        User->>App: 補足情報を入力
        App->>Func: 補足内容と元データを送信
        Func->>LLM: 妥当性とマスタ整合を確認
        LLM-->>Func: 修正案または確定案を返却
        Func->>DV: 保全DBを更新しフラグをOFFに変更
    else フラグがない場合
        App-->>User: 通常の閲覧画面を表示
    end
```

---

## 16. システムアーキテクチャ

```mermaid
graph TD
    User([現場作業員]) -->|入力と検索| App[Power Apps
保全アプリ]
    App -->|トリガ| Flow[Power Automate]
    Flow -->|API Request| Func[Azure Functions
LLM主体エンジン]

    subgraph AI_Engine[LLM主体 AI エンジン]
      Func -->|構造化と補正| LLM[Azure OpenAI
GPT-5]
      Func -->|Embedding| Emb[Azure OpenAI
Embeddings]
      Func -->|類似検索| Search[Azure AI Search]
    end

    subgraph DataPlatform[Data Platform]
      Func -->|CRUD操作| DV[(Dataverse
保全DBとマスタと辞書)]
      DV <-->|同期| Search
    end

    subgraph Security[Security]
      User --> Entra[Entra ID
旧Azure AD]
      App --> Entra
      Func --> Entra
    end
```

---

## 17. Power Platform ライセンス選択ガイド

### Case A：全社・全部署で広く活用

- Power Apps Premium  
- 約2,500円/ユーザー/月  
- 多数のアプリを横展開する場合に最適。  

### Case B：特定部署・特定アプリのみ

- Power Apps Per App  
- 約625円/ユーザー/アプリ/月  
- スモールスタートに最適。  

### Case C：利用頻度がごく少ない

- Pay-as-you-go  
- 約1,250円/アクティブユーザー/アプリ/月  
- 使った月だけ課金。  

---

## 18. プロジェクトロードマップ（3ヶ月）

```mermaid
gantt
    title 3ヶ月導入スケジュール
    dateFormat  YYYY-MM-DD

    section データ整備
    Seed生成(LLM PoC)      :active, 2026-02-01, 20d
    マスタ検証(人手)       :2026-02-21, 10d
    Scale全展開(Batch)     :2026-03-01, 15d
    運用フロー設計         :2026-03-10, 10d

    section アプリ開発
    Azure基盤構築         :2026-02-01, 20d
    PowerApps画面実装     :2026-02-20, 30d
    結合テストと教育       :2026-03-20, 10d
```

---

## 19. 概算費用とROI

### 概算費用（例）

- 合計：**1,300万円（税抜）**  
  - PM：120万円  
  - Data Scientist（AI・マスタ生成）：625万円  
  - Engineer（Power Platform・Azure基盤）：450万円  
  - 予備費：105万円  

### ROIイメージ

1. **コスト回避（既存データクレンジング）**  
   - 23万件 × 5分/件 = 約19,166時間。  
   - 1人が不眠不休で約2年強、または10年かけて行う作業を、  
     約3ヶ月のプロジェクト＋AI処理で完了。  

2. **業務削減（入力・調査時間短縮）**  
   - 50名 × 15分/日 × 240日 = 3,000時間/年。  
   - 高品質データとRAG検索により、調査・入力時間を削減。  

3. **将来の追加効果（スコープ外）**  
   - クレンジング済みデータを用いた予防保全／予兆検知への発展により、  
     設備停止時間の削減・生産性向上が期待可能（別途検討）。  

---

## 20. 将来の発展イメージ（本スコープ外：予防保全）

### 本提案のスコープ

- 既存23万件の保全データのクレンジングとマスタ生成。  
- AI入力支援つき保全アプリによる「勝手に整う」運用の実現。  

### 将来の発展（別フェーズ）

- クレンジング済み保全データ  
  ＋ 設備モニタリングデータ（振動・温度・電流値 等）  
  を組み合わせ、  
  - 故障前の「前兆パターン」を分析。  
  - 予兆段階でアラートを出す仕組みの構築。  

### 位置づけ

- 現フェーズの成果（高品質な保全データとマスタ）が揃って初めて実現可能。  
- 本提案書ではスコープ外とし、別途PoC・ロードマップをご提案可能。  

---

## 21. 次のアクション（Next Steps）

1. **スコープ・方針のご確認**  
   - 3つの提案要旨（①AIクレンジング ②AI入力支援 ③“育てる”運用）の方向性。  

2. **事前準備の確認**  
   - 分析用サンプルデータ（CSV、機密はマスキング可）のご提供。  
   - Azure / Microsoft 365 テナント状況の確認。  

3. **プロジェクト体制の確定**  
   - 貴社側の窓口・キーユーザーのご指名。  
   - Kickoffミーティング日程の調整。  

**口頭補足例**

> 「まずは10％のサンプルデータで、どの程度の精度でマスタを自動生成できるかをお見せし、その上で本格展開をご判断いただく形も可能です。」

---

## 22. 体制とDATUM STUDIOの強み

### 体制（例）

- PM（1名）：全体統括、進捗管理、ステークホルダー調整。  
- Data Scientist（1名）：LLM主導マスタ生成・クレンジングアルゴリズム設計・検証。  
- Power Platform Engineer（1名）：Power Apps / Power Automate / Dataverse / Azure基盤構築。  

### DATUM STUDIOの強み

- データ分析とアプリ開発の両輪を持つ体制。  
- 製造業におけるAI活用（予兆保全、品質検査、需要予測等）の実績。  
- Azure OpenAI / Power Platform を活用したエンタープライズDX案件の経験値。  

---
