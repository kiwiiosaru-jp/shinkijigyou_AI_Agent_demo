# 保全業務DXおよび既存データ資産化プロジェクト 提案書（Markdown版）

## 目次

1. タイトル  
2. 本日のアジェンダ  
3. プロジェクト背景（弊社理解）  
4. ご提案サマリ（3つの柱）  
5. 現状の課題：負の連鎖（Vicious Cycle）  
6. 技術アプローチの全体像（LLM主導：3フロー構成）  
7. 提案要旨①の深掘り：AIクレンジング＆マスタ自動生成  
8. アルゴリズム詳細（ラインマスタ：文字列距離＋LLM）  
9. アルゴリズム詳細（設備・部品マスタ：LLM＋Embedding）  
10. アルゴリズム詳細（分類・標準用語辞書）  
11. 提案要旨②の深掘り：RAG検索＆AI入力支援アプリ  
12. 提案要旨③の深掘り：少し試す→確かめる→全体に広げる と “育てる”運用  
13. 「育てる」① 初期構築でマスタを育てる（10％ → 90％）  
14. 「育てる」② 運用しながらマスタを育てる  
15. 「育てる」③ 保全報告データを運用の中で育てる  
16. システムアーキテクチャ  
17. Power Platform ライセンス選択ガイド  
18. プロジェクトロードマップ（3ヶ月）  
19. 概算費用とROI  
20. 将来の発展イメージ（本スコープ外：予防保全）  
21. 次のアクション（Next Steps）  
22. 体制とDATUM STUDIOの強み  

**Appendix（技術メンバー向け）**

A-1. 全体の4フロー構成（技術者視点）  
A-2. Batch A：Seed マスタ生成バッチ（10％サンプル）  
A-3. Batch B：マスタ拡張バッチ（残り90％でマスタを育てる）  
A-4. Batch C：本番クレンジングバッチ（v2マスタで全件クレンジング）  
A-5. Flow D：オンラインAI入力補助フロー（運用）  

---

## 1. タイトル

**タイトル**  
保全業務DXおよび既存データ資産化プロジェクトのご提案  

**サブタイトル**  
Power Platform × Generative AI (GPT-5) による「ナレッジ駆動型保全」への変革  

**宛名**  
いすゞ自動車株式会社 御中  

**日付**  
2026年1月  

**提案者**  
DATUM STUDIO  

---

## 2. 本日のアジェンダ

1. プロジェクト背景とご提案サマリ  
2. 現状の課題：「負の連鎖」と23万件データの状況  
3. 技術アプローチの全体像（LLM主導：3フロー構成）  
4. 提案要旨①：AIクレンジング＆マスタ自動生成  
5. 提案要旨②：RAG検索＆AI入力支援アプリ  
6. 提案要旨③：  
   「少し試す → 確かめる → 全体に広げる」と  
   マスタ／保全データを“育てる”運用  
7. システムアーキテクチャ  
8. Power Platform ライセンスとロードマップ  
9. 概算費用とROI  
10. 将来の発展イメージ（本スコープ外：予防保全）  
11. 次のアクション／体制と実績  

---

## 3. プロジェクト背景（弊社理解）

### ヘッダーメッセージ

> 「23万件の埋蔵データの資産化」と「現場入力業務の高度化」の課題に対し、Azure OpenAI × Power Platformによる保全ナレッジDX基盤の構築をご提案いたします。  
> 生成AIによるデータクレンジングの自動化と、検索・入力支援アプリの実装を通じて、現場の負荷を増やさずに高品質な保全データを継続的に蓄積できる仕組みを実現します。

### 貴社の現状（弊社理解）

- 既存の**保全履歴23万件**は、すでにCSV/DBとして **構造化されている**。  
- しかし、  
  - 表記揺れ（例：モータ／モーター／Mtr）  
  - 略語・誤字  
  - 項目のズレ（原因欄に処置内容が入っている 等）  
  により、**そのままでは信頼して検索・分析に使えない**。  
- 人手で全件修正すると、  
  - 23万件 × 5分/件 = 約19,000時間  
  - 現場では実質的に対応不可能。  

### 負の連鎖の構造

- 過去事例が検索でヒットしない → 毎回ゼロから調査・復旧。  
- 入力ルールも徹底しきれず、**新たな揺らぎデータが毎日増える**。  
- 時間が経つほど、「データ量は増えるが、活用難易度だけ上がる」状態に。  

---

## 4. ご提案サマリ（3つの柱）

### 提案要旨①：AIクレンジング＆マスタ自動生成による「23万件の一括資産化」

- GPT-5による構造化・補正エンジンと、  
  Embedding＋クラスタリングによる名寄せロジックにより、  
  既存23万件データを自動クレンジング。  
- 設備・現象・原因・処置マスタ＋標準用語辞書を自動生成。  
- 約19,000時間相当の人手作業をAIで代替。  

### 提案要旨②：RAG検索＆AI入力支援アプリによる「勝手に整うデータ運用」

- Power Apps上に、Azure OpenAIと連携した検索・入力支援アプリを構築。  
- 現場は「自然な日本語で入力するだけ」。  
  → 過去類似事例の提示・標準用語への変換・構造化補完が自動で実行。  
- **「現場が楽になればなるほど、データが勝手に整っていく」**サイクルを実現。  

### 提案要旨③：  
### 「少し試す → 確かめる → 全体に広げる」と  
### マスタ／保全データを少しずつ“育てる”運用設計

- いきなり全件自動ではなく、まず**約10％のサンプルでAIがマスタのたたき台を作成**。  
- 人が確認したうえで、残りの90％に一括適用し、処理中に見つかる「新しい設備・事象」をマスタに追加。  
- 運用開始後も、  
  - 新しい設備・事象が出てきたらアプリからマスタに追加。  
  - 初期クレンジングで埋めきれなかった項目は「要確認」として残し、  
    類似案件検索のタイミングで現場が**“ついでに補正”**できる。  
- これにより、**マスタ（用語集）と保全報告データの両方を、運用の中で育てていく**。  

---

## 5. 現状の課題：負の連鎖（Vicious Cycle）

### 顧客の真のペイン

> 「データを使って業務を効率化したいが、検索しても過去の類似事象がヒットしない。  
>  結果として入力の手間も減らず、ナレッジも活用できない。」

### 負の連鎖のメカニズム

1. 過去データに表記揺れ・項目ズレ・欠損が多く、検索してもヒットしない。  
2. データを直したいが、現場にその工数（約19,000時間）は確保できない。  
3. 既存の揺らぎデータは放置され、日々の入力で新たな揺らぎが再生産。  
4. 時間が経つほど、データ量は増えるが活用困難さは増していく。  

### ブレークスルー

- 現場が確保できない「約19,000時間」の工数を、  
  AI（GPT-5）という**仮想労働力**で肩代わりし、  
  このループを断ち切る。  

---

## 6. 技術アプローチの全体像（LLM主導：3フロー構成）

### 3つの主要フロー（お客様向けの整理）

本提案の中で動く処理フローは、現場から見ると次の **3つだけ** に見えるように整理します。

1. **バッチ1：マスタ初期生成バッチ**  
   - 既存データの一部（約10％サンプル）を使って、  
     - ラインマスタ  
     - 設備・部品マスタ  
     - 現象／原因／処置マスタ  
     - 標準用語辞書（略語・揺らぎ → 正式名称）  
     を **自動生成し、人が確認して「初期マスタ」として確定** するバッチ処理。

2. **バッチ2：初期データクレンジングバッチ**  
   - バッチ1で確定したマスタと標準用語辞書を使って、  
     既存23万件すべてを **一括クレンジング** するバッチ処理。  
   - マスタに当てはまらないものや、AIの自信度が低いものは、  
     「マスタ追加候補」や「要確認フラグ付きデータ」としてマーク。

3. **運用フロー（オンライン）：AI入力補助付きの保全データ登録**  
   - 日々の業務では、Power Apps上で保全データを入力するたびに、  
     GPT-5がマスタを参照しながら  
     - 標準用語変換  
     - 構造化（設備・現象・原因・処置 分解）  
     - 不足項目の質問  
     を行う。  
   - このオンライン運用の中で、  
     - 新しい設備・事象が出た場合のマスタ追加  
     - 初期クレンジングで埋めきれなかった項目の“ついで補正”  
     も行われ、「マスタ」と「保全データ」の両方を継続的に育てる。

### 全体像フロー図（3フロー構成）

```mermaid
flowchart LR
    subgraph Batch1[バッチ1：マスタ初期生成]
        A1[既存DB(23万件)] -->|10%サンプル| A2[LLM構造化とクラスタ]
        A2 --> A3[マスタ案生成]
        A3 --> A4[人手レビューで初期マスタ確定]
    end

    subgraph Batch2[バッチ2：初期データクレンジング]
        A4 --> B1[クレンジングバッチ]
        A1 -->|全件| B1
        B1 --> B2[クレンジング済DB
要確認フラグ付きデータ含む]
        B1 --> B3[マスタ追加候補リスト]
    end

    subgraph Online[運用フロー：AI入力補助]
        User[現場作業員] --> App[保全アプリ
AI入力補助]
        App -->|入力内容| LLM[LLM構造化と標準用語提案]
        LLM -->|マスタ参照| A4
        App -->|確定データ| B2
        App -->|新設備と新現象| A4
        App -->|要確認データ閲覧時の補正| B2
    end
```

---

## 7. 提案要旨①の深掘り：AIクレンジング＆マスタ自動生成

### 7-1. ゴールと処理の順番

**ゴール**

1. まず、既存データから  
   - ラインマスタ  
   - 設備・部品マスタ  
   - 現象／原因／処置マスタ  
   - 標準用語辞書（略語・揺らぎ → 正式名称）  
   を **AIで自動生成し、担当者が軽くレビューして「初期マスタ」として確定する**。  

2. 次に、その **確定マスタを参照しながら** 既存23万件の保全データを  
   - 項目ズレの補正  
   - 表記揺れ・略語の標準化  
   - 欠損の補完（可能な範囲）  
   によってクレンジングし、「信頼して検索・分析・入力支援に使えるデータ」にする。

---

### 7-2. フェーズ1：各種マスタの自動生成（バッチ1）

1. 既存DBから、代表性を確保した **約10％のサンプルデータ** を抽出。  
2. GPT-5で各レコードを構造化し、  
   - ライン  
   - 設備名・別名  
   - 部品  
   - 現象  
   - 原因  
   - 処置  
   などの候補を抽出。  
3. 抽出用語を Embedding してクラスタリングし、「似たもの同士」をグループ化。  
4. 各クラスタに対して GPT-5 が  
   - 標準名称（正式名）  
   - 別名リスト  
   - 分類（現象の大・中・小分類 など）  
   を提案。  
5. 担当者がクラスタ単位でざっと確認し、**初期マスタとして確定**。

---

### 7-3. フェーズ2：確定マスタを用いた一括クレンジング（バッチ2）

1. フェーズ1で確定したマスタと標準用語辞書を「正解テーブル」として準備。  
2. 既存23万件すべてに対してGPT-5を適用し、  
   - 各項目（現象／原因／処置／設備等）を読み直す  
   - 項目ズレを検知し、正しい欄に振り分ける  
   - 用語を標準用語辞書にマッピングして表記揺れを解消  
3. マスタにマッチしない用語や、AIの自信度が低い推論結果は、  
   - 「マスタ追加候補」としてマスタ側に記録  
   - 「要確認フラグ付きデータ」として保全側に記録  
4. クレンジング済みデータを、  
   - RAG検索  
   - AI入力補助  
   - 集計・分析  
   のベースとなる「信頼できる保全履歴テーブル」として保存。

---

### 7-4. 全体フロー（2フェーズ構成のシーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(23万件)
    participant Sampler as サンプル抽出(約10%)
    participant LLM as GPT-5
    participant EMB as Embeddingクラスタ
    participant Reviewer as 担当者
    participant MAST as マスタDBと辞書
    participant Batch as クレンジングバッチ
    participant OUT as クレンジング済DB

    %% フェーズ1：マスタ初期生成
    DB->>Sampler: 全データを渡す
    Sampler->>LLM: サンプルデータを順次送信
    loop サンプルレコード
        LLM-->>Sampler: 構造化結果と用語候補を返却
        Sampler->>EMB: 抽出用語を登録
    end
    EMB->>LLM: クラスタ情報を送信
    LLM-->>MAST: マスタ案と標準用語案を出力
    Reviewer->>MAST: マスタ案を確認して修正
    MAST->>MAST: 確定マスタと辞書として保存

    %% フェーズ2：マスタを使った一括クレンジング
    MAST->>Batch: 確定マスタと辞書を提供
    DB->>Batch: 全レコードを読み込み
    loop 全レコード
        Batch->>LLM: レコード内容とマスタ情報を送信
        LLM-->>Batch: 項目補正と用語マッピング結果を返却
        alt マスタにマッチし信頼度高
            Batch->>OUT: 補正済レコードとして保存
        else マスタにマッチせずまたは信頼度低
            Batch->>OUT: 要確認フラグ付きで保存
            Batch->>MAST: マスタ追加候補として別テーブルに登録
        end
    end
```

---

## 8. アルゴリズム詳細：ラインマスタ（文字列距離＋LLM）

### 目的

- 「Aライン」「A-Line」「Line A」などの揺らぎを名寄せし、  
  **ラインを一意に識別**できるようにする。  

### 考え方

- ライン名は意味よりも**記号的な違い**が重要。  
- Embeddingだけに頼ると、A/Bラインが「同じ工場のライン」として近くなり過ぎるリスク。  
- そのため、  
  - 文字列正規化（全角/半角・記号・大小文字）  
  - Levenshtein距離でのグルーピング  
  - 最後にLLMで正式名称決定  
  というハイブリッド方式を採用。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(ライン情報)
    participant LineETL as ライン名抽出処理
    participant Norm as 文字列正規化
    participant Cls as 距離ベースクラスタ
    participant LLM as GPT-5
    participant MLine as ラインマスタと辞書

    DB->>LineETL: ライン名候補を抽出
    LineETL->>Norm: ライン文字列を正規化
    Norm-->>Cls: 正規化済みライン名一覧を渡す
    Cls->>Cls: 距離計算とクラスタリングを実行
    loop 各クラスタ
        Cls->>LLM: クラスタ内候補と簡易文脈を送信
        LLM-->>Cls: 正式名称と別名リストを返却
        Cls->>MLine: ラインマスタに登録
        MLine->>MLine: 別名から正式名称への辞書を更新
    end
```

---

## 9. アルゴリズム詳細：設備・部品マスタ（LLM＋Embedding）

### 目的

- 文章や項目の中に埋もれている  
  「設備」「部品」を抽出し、  
  - 設備マスタ  
  - 部品マスタ  
  - 設備＞部品の親子関係  
  を構造化する。  

### ポイント

- GPT-5が  
  - line（ライン）  
  - equipment（設備）  
  - part（部品）  
  などを文脈から抽出。  
- 抽出された用語をEmbeddingし、クラスタリングで名寄せ。  
- GPT-5で、クラスタごとの代表名（標準設備名）と親子関係を決定。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant ETL as 設備候補抽出
    participant LLM as GPT-5
    participant EMB as Embeddingクラスタ
    participant MEquip as 設備と部品マスタDB

    DB->>ETL: レコードを取得
    loop 各レコード
        ETL->>LLM: テキストと既存設備名を送信
        LLM-->>ETL: 抽出結果をJSON形式で返却
        ETL->>EMB: 設備と部品の用語をクラスタ用に登録
    end
    EMB->>LLM: 用語クラスタ一覧を送信
    LLM-->>MEquip: 標準設備名と標準部品名と親子関係を決定
    MEquip->>MEquip: 設備マスタと部品マスタと別名辞書を更新
```

---

## 10. アルゴリズム詳細：分類・標準用語辞書

### 目的

- 現象・原因・処置を、  
  - 大分類  
  - 中分類  
  - 小分類  
  の階層に整理（Taxonomy）。  
- 略語・俗語を含む表記揺れを、標準用語辞書に集約。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as クレンジング候補DB
    participant ETL as テキスト抽出
    participant LLM as GPT-5
    participant EMB as Embeddingクラスタ
    participant MClass as 分類マスタ
    participant Dict as 標準用語辞書

    DB->>ETL: 現象と原因と処置を取得
    loop 各レコード
        ETL->>LLM: テキストを送信
        LLM-->>ETL: 現象と原因と処置を抽出
        ETL->>EMB: 用語をEmbedding登録
    end
    EMB->>LLM: クラスタごとの用語リストを送信
    LLM-->>MClass: 大分類と中分類と小分類のラベル案を生成
    LLM-->>Dict: 標準用語と別名の対応表を生成
    MClass->>MClass: 分類マスタを更新
    Dict->>Dict: 標準用語辞書を更新
```

---

## 11. 提案要旨②の深掘り：RAG検索＆AI入力支援アプリ

### コンセプト

> 「現場が自由に入力するだけで、裏でAIが標準化と構造化を代行する」

### 主な機能

1. **RAGによる類似案件提示**  
2. **インテリジェント入力支援（標準用語化・構造化・不足項目の補完）**  
3. **「要確認」データの自然な解消**  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps保全アプリ
    participant Flow as Power Automate
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant Search as Azure AI Search
    participant DV as Dataverse保全DB

    User->>App: 現象や対応内容を入力
    App->>Flow: 入力テキストを送信
    Flow->>Func: APIリクエストを送信
    Func->>LLM: 入力テキストとマスタ情報を渡す
    LLM-->>Func: 構造化結果と標準用語候補と不足項目を返却
    Func->>Search: 類似案件検索を実行
    Search-->>Func: 類似事例一覧を返却
    Func-->>App: 類似事例と標準用語案と不足項目の質問を返却
    App-->>User: 変換案や確認メッセージを表示
    User->>App: 承認や修正を入力
    App->>Flow: 確定データを送信
    Flow->>DV: 保全DBとマスタと辞書を更新
```

---

## 12. 提案要旨③の深掘り：  
## 「少し試す → 確かめる → 全体に広げる」と  
## マスタ／保全データを“育てる”運用

### 3つの「育てる」

1. **初期構築でマスタを育てる（10％ → 90％）**  
2. **運用しながらマスタを育てる（新しい設備・事象への対応）**  
3. **運用しながら保全報告データを育てる（埋まっていない項目を“ついでに”補正）**  

---

## 13. 「育てる」① 初期構築でマスタを育てる（10％ → 90％）

### ステップ1：データの約10％で「たたき台」を作る

- 23万件のうち、ライン・設備・年度のバランスを見ながら約10％を抽出。  
- GPT-5で構造化し、設備／現象／原因／処置マスタの**たたき台**を自動生成。  

### ステップ2：たたき台だけ人がチェックする

- 10％分から作られたマスタ候補を、担当者がざっと確認。  
- 全23万件を見るのではなく、**代表例だけを見るので負荷が小さい**。  

### ステップ3：残り90％に広げながら、未知のものをマスタに追加

- 検証済みマスタを「正解」として、残り90％を一括処理。  
- 処理中に、既存マスタに当てはまらない新しい設備・事象が出てきたら、  
  AIが「マスタ追加候補」として自動登録。  
- 後から「マスタ追加候補」一覧を人が見て、採用／不採用を決めることで、  
  **マスタが一段階レベルアップ**していく。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant DB as 既存DB(23万件)
    participant Sampler as サンプル抽出(10%)
    participant LLM as GPT-5
    participant EMB as Embeddingクラスタ
    participant Reviewer as 担当者
    participant MAST as マスタDB
    participant Batch as 全体バッチ処理

    DB->>Sampler: 全データを渡す
    Sampler->>LLM: サンプルデータを送信
    loop サンプルデータ
        LLM-->>Sampler: 抽出用語と構造化結果を返却
        Sampler->>EMB: 抽出用語を登録
    end
    EMB->>LLM: クラスタ情報を渡す
    LLM-->>MAST: マスタ骨子案を生成
    Reviewer->>MAST: マスタ骨子案を確認して修正
    MAST->>Batch: 確定マスタを提供
    Batch->>DB: 残り90%を読み込み
    loop 各レコード
        Batch->>LLM: レコードと確定マスタを送信
        LLM-->>Batch: マッチング結果と未知候補を返却
        alt 既存マスタにマッチ
            Batch->>DB: クレンジング済として更新
        else 未知候補
            Batch->>MAST: マスタ追加候補として登録
        end
    end
```

---

## 14. 「育てる」② 運用しながらマスタを育てる

### 状況

- 新しい設備が導入された。  
- これまで起きていなかった新種の現象が発生した。  

### 流れ

1. 現場がアプリ上で新しい設備・現象を入力。  
2. GPT-5が既存マスタと似ているかを判定。  
3. どれにも当てはまらなければ、  
   - 「新しい設備として登録しますか？」  
   - 「新しい現象分類として追加しますか？」  
   と提案。  
4. 承認されると、その場でマスタに反映。  
   - 以後は同じ表現が出てきても、自動で同じマスタIDに紐づく。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant MAST as マスタDB

    User->>App: 新しい設備や現象を含む報告を入力
    App->>Func: 入力内容を送信
    Func->>LLM: 入力内容と既存マスタを送信
    LLM-->>Func: 類似マスタ候補と類似度とコメントを返却
    alt 類似度が高い場合
        Func-->>App: 既存マスタとの紐づけ案を表示
        User->>App: 案を承認
        App->>MAST: 既存マスタIDへの紐づけを登録
    else 新規マスタが妥当な場合
        Func-->>App: 新しいマスタとして登録するか確認
        User->>App: 登録を承認
        App->>MAST: 新しい設備や現象マスタを登録
    end
```

---

## 15. 「育てる」③ 保全報告データを運用の中で育てる

### 前提

- 初期クレンジングの段階で、  
  GPT-5のconfidenceが低い項目は無理に埋めず、  
  - フィールドは空欄のまま。  
  - 「要確認」フラグをON。  
  としてナレッジDBに登録。  

### 日常運用の中での「ついでに補正」

1. 現場が類似案件を検索し、検索結果一覧から案件を開く。  
2. 開いた案件が「要確認」フラグ付きの場合、  
   - 「この案件は原因が未入力です。わかる範囲で補足しますか？」  
     と小さなメッセージを表示。  
3. 担当者が余裕のある範囲で、1〜2項目だけ補足入力。  
4. GPT-5が入力内容をチェックし、  
   - 保全報告データに反映。  
   - 必要に応じてマスタ／辞書にも反映。  
5. 以後、その案件は**「要確認」から「確定済」へ昇格**。  

### 処理フロー（シーケンス図）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps
    participant Search as Azure AI Search
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant DV as Dataverse保全DB

    User->>App: 類似案件を検索
    App->>Search: 検索クエリを送信
    Search-->>App: 検索結果を返却
    User->>App: 要確認案件を選択
    App->>DV: 案件詳細を取得
    alt 要確認フラグがある場合
        App-->>User: 原因が未入力ですと表示し補足を促す
        User->>App: 補足情報を入力
        App->>Func: 補足内容と元データを送信
        Func->>LLM: 妥当性とマスタ整合を確認
        LLM-->>Func: 修正案または確定案を返却
        Func->>DV: 保全DBを更新しフラグをOFFに変更
    else フラグがない場合
        App-->>User: 通常の閲覧画面を表示
    end
```

---

## 16. システムアーキテクチャ

```mermaid
graph TD
    User([現場作業員]) -->|入力と検索| App[Power Apps
保全アプリ]
    App -->|トリガ| Flow[Power Automate]
    Flow -->|API Request| Func[Azure Functions
LLMエンジン]

    subgraph AI_Engine[LLM主体 AI エンジン]
      Func -->|構造化と補正| LLM[Azure OpenAI
GPT-5]
      Func -->|Embedding| Emb[Azure OpenAI
Embeddings]
      Func -->|類似検索| Search[Azure AI Search]
    end

    subgraph DataPlatform[Data Platform]
      Func -->|CRUD操作| DV[(Dataverse
保全DBとマスタと辞書)]
      DV <-->|同期| Search
    end

    subgraph Security[Security]
      User --> Entra[Entra ID
旧Azure AD]
      App --> Entra
      Func --> Entra
    end
```

---

## 17. Power Platform ライセンス選択ガイド

### Case A：全社・全部署で広く活用

- Power Apps Premium  
- 約2,500円/ユーザー/月  
- 多数のアプリを横展開する場合に最適。  

### Case B：特定部署・特定アプリのみ

- Power Apps Per App  
- 約625円/ユーザー/アプリ/月  
- スモールスタートに最適。  

### Case C：利用頻度がごく少ない

- Pay-as-you-go  
- 約1,250円/アクティブユーザー/アプリ/月  
- 使った月だけ課金。  

---

## 18. プロジェクトロードマップ（3ヶ月）

```mermaid
gantt
    title 3ヶ月導入スケジュール
    dateFormat  YYYY-MM-DD

    section データ整備
    Seed生成LLM PoC      :active, 2026-02-01, 20d
    マスタ検証人手       :2026-02-21, 10d
    全件クレンジングBatch :2026-03-01, 15d
    運用フロー設計       :2026-03-10, 10d

    section アプリ開発
    Azure基盤構築         :2026-02-01, 20d
    PowerApps画面実装     :2026-02-20, 30d
    結合テストと教育       :2026-03-20, 10d
```

---

## 19. 概算費用とROI

### 概算費用（例）

- 合計：**1,300万円（税抜）**  
  - PM：120万円  
  - Data Scientist（AI・マスタ生成）：625万円  
  - Engineer（Power Platform・Azure基盤）：450万円  
  - 予備費：105万円  

### ROIイメージ

1. **コスト回避（既存データクレンジング）**  
   - 23万件 × 5分/件 = 約19,166時間。  
   - 1人が不眠不休で約2年強、または10年かけて行う作業を、  
     約3ヶ月のプロジェクト＋AI処理で完了。  

2. **業務削減（入力・調査時間短縮）**  
   - 50名 × 15分/日 × 240日 = 3,000時間/年。  
   - 高品質データとRAG検索により、調査・入力時間を削減。  

3. **将来の追加効果（スコープ外）**  
   - クレンジング済みデータを用いた予防保全／予兆検知への発展により、  
     設備停止時間の削減・生産性向上が期待可能（別途検討）。  

---

## 20. 将来の発展イメージ（本スコープ外：予防保全）

### 本提案のスコープ

- 既存23万件の保全データのクレンジングとマスタ生成。  
- AI入力支援つき保全アプリによる「勝手に整う」運用の実現。  

### 将来の発展（別フェーズ）

- クレンジング済み保全データ  
  ＋ 設備モニタリングデータ（振動・温度・電流値 等）  
  を組み合わせ、  
  - 故障前の「前兆パターン」を分析。  
  - 予兆段階でアラートを出す仕組みの構築。  

### 位置づけ

- 現フェーズの成果（高品質な保全データとマスタ）が揃って初めて実現可能。  
- 本提案書ではスコープ外とし、別途PoC・ロードマップをご提案可能。  

---

## 21. 次のアクション（Next Steps）

1. **スコープ・方針のご確認**  
   - 3つの提案要旨（①AIクレンジング ②AI入力支援 ③“育てる”運用）の方向性。  

2. **事前準備の確認**  
   - 分析用サンプルデータ（CSV、機密はマスキング可）のご提供。  
   - Azure / Microsoft 365 テナント状況の確認。  

3. **プロジェクト体制の確定**  
   - 貴社側の窓口・キーユーザーのご指名。  
   - Kickoffミーティング日程の調整。  

**口頭補足例**

> 「まずは10％のサンプルデータで、どの程度の精度でマスタを自動生成できるかをお見せし、その上で本格展開をご判断いただく形も可能です。」

---

## 22. 体制とDATUM STUDIOの強み

### 体制（例）

- PM（1名）：全体統括、進捗管理、ステークホルダー調整。  
- Data Scientist（1名）：LLM主導マスタ生成・クレンジングアルゴリズム設計・検証。  
- Power Platform Engineer（1名）：Power Apps / Power Automate / Dataverse / Azure基盤構築。  

### DATUM STUDIOの強み

- データ分析とアプリ開発の両輪を持つ体制。  
- 製造業におけるAI活用（予兆保全、品質検査、需要予測等）の実績。  
- Azure OpenAI / Power Platform を活用したエンタープライズDX案件の経験値。  

---

# Appendix：技術メンバー向け詳細版（4フロー構成）

---

## Appendix A-1. 全体の4フロー構成（技術者視点）

```mermaid
flowchart TB
    A0[既存DB(23万件)] -->|10%サンプル| A[Batch A
Seedマスタ生成]
    A0 -->|残り90%| B[Batch B
マスタ拡張]
    A --> M[マスタDB v1]
    B --> M2[マスタDB v2最終版]

    A0 --> C[Batch C
本番クレンジング]
    M2 --> C
    C --> OUT[クレンジング済DB
要確認フラグ付きデータ]

    subgraph Online[Flow D
オンラインAI入力補助]
        User[現場作業員] --> App[保全アプリ]
        App --> LLM[LLM API]
        LLM --> M2
        App --> OUT
        App --> M2
    end
```

---

## Appendix A-2. Batch A：Seed マスタ生成バッチ（10％サンプル）

### 目的

- 10％サンプルから、各種マスタの「たたき台（v1）」を作る。  
- レーンは内部的に3つ：  
  - レーン1：ラインマスタ  
  - レーン2：設備・部品マスタ  
  - レーン3：現象／原因／処置＋標準辞書  

### シーケンス図（Batch A 全体）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant Sampler as サンプル抽出10%
    participant LLM as GPT-5
    participant EMB as Embeddingクラスタ
    participant Reviewer as 担当者
    participant MAST as マスタDB v1

    DB->>Sampler: 全レコードを渡す
    Sampler-->>LLM: 抽出した10%サンプルを順次送信

    loop サンプルレコード
        LLM-->>Sampler: 構造化結果を返却 ライン設備現象原因処置など
        Sampler->>EMB: 抽出用語をクラスタ用バッファに登録
    end

    EMB->>LLM: レーン別クラスタ情報を送信 ライン設備現象など
    LLM-->>MAST: 各クラスタに対するマスタ案を出力 標準名称別名分類ラベルなど

    Reviewer->>MAST: マスタ案を確認する
    Reviewer->>MAST: 名称修正やクラスタ統合分割などを反映
    MAST->>MAST: 修正後のマスタをv1として確定保存
```

---

## Appendix A-3. Batch B：マスタ拡張バッチ（残り90％でマスタを育てる）

### 目的

- v1マスタを使って残り90％をざっとなぞりながら、  
  - 既存マスタにマッチしないパターンを検出  
  - 新しい設備・現象候補を洗い出す  
- その結果を反映して **マスタDBをv2（拡張版）に更新** する。

### シーケンス図（Batch B）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant Selector as 残り90選別
    participant MASTv1 as マスタDB v1
    participant LLM as GPT-5
    participant EMB2 as 追加Embeddingクラスタ
    participant Reviewer as 担当者
    participant MASTv2 as マスタDB v2

    DB->>Selector: 全レコードを渡す
    Selector-->>Selector: 10%で使用済みIDを除外
    Selector-->>LLM: 残り90%レコードを順次送信

    loop 残り90%レコード
        LLM->>MASTv1: 既存マスタ情報を参照
        LLM-->>Selector: マスタID候補と未マッチ用語を返却
        alt 既存マスタにマッチ
            Selector->>Selector: マスタIDを記録して統計に利用
        else 未マッチ用語あり
            Selector->>EMB2: 未マッチ用語をクラスタ用に登録
        end
    end

    EMB2->>LLM: 未マッチ用語クラスタ情報を送信
    LLM-->>MASTv2: 新規マスタ候補一覧を出力 候補名称候補クラスタ関連情報など

    Reviewer->>MASTv2: 新規マスタ候補を確認
    Reviewer->>MASTv2: 採用不採用名称修正既存マスタ統合などを決定

    MASTv1->>MASTv2: v1マスタをコピー
    MASTv2->>MASTv2: 新規マスタを反映してv2として確定
```

---

## Appendix A-4. Batch C：本番クレンジングバッチ（v2マスタで全件クレンジング）

### 目的

- v2マスタ（拡張済み）を使って、23万件すべてに対し本番クレンジングを実行。  
- 結果を **「クレンジング済DB」＋「要確認フラグ付きデータ」** として保存する。

### シーケンス図（Batch C）

```mermaid
sequenceDiagram
    participant DB as 既存DB
    participant MASTv2 as マスタDB v2
    participant CleanBatch as 本番クレンジングバッチ
    participant LLM as GPT-5
    participant OUT as クレンジング済DB

    DB->>CleanBatch: 全レコードを読み込み
    MASTv2->>CleanBatch: v2マスタと標準用語辞書をロード

    loop 全レコード
        CleanBatch->>LLM: レコード内容とマスタ情報を送信
        LLM-->>CleanBatch: 補正結果を返却 項目補正用語マッピング信頼度など

        alt 信頼度が高くマスタにマッチ
            CleanBatch->>OUT: 確定レコードとして保存 ステータス確定
        else 信頼度が低いまたはマスタにマッチしない
            CleanBatch->>OUT: 要確認フラグ付きで保存 元値を保持
            CleanBatch->>MASTv2: 必要に応じてマスタ追加候補として別テーブルに記録
        end
    end
```

---

## Appendix A-5. Flow D：オンラインAI入力補助フロー（運用）

### 目的

- 日常運用で保全データを登録する際に、  
  - マスタDB(v2) をリアルタイムに参照  
  - LLMで構造化＆標準化＆不足項目プロンプト  
  を行い、  
- 同時に、  
  - 新しい設備・現象のマスタ追加  
  - 要確認フラグ付きデータの“ついで補正”  
  を行うことで、マスタと保全データを継続的に育てる。

### シーケンス図（Flow D）

```mermaid
sequenceDiagram
    participant User as 現場作業員
    participant App as Power Apps保全アプリ
    participant Func as Azure Functions
    participant LLM as GPT-5
    participant MASTv2 as マスタDB v2
    participant OUT as クレンジング済DB

    User->>App: 現象や対応内容を自由入力
    App->>Func: 入力内容を送信

    Func->>MASTv2: 最新マスタと辞書を参照
    Func->>LLM: 入力テキストとマスタ情報を送信
    LLM-->>Func: 構造化結果と標準用語候補と不足項目を返却

    Func-->>App: 類似案件候補標準用語案不足項目質問を返却
    App-->>User: 変換案や確認メッセージを表示
    User->>App: 提案の承認修正不足項目入力

    App->>Func: ユーザー確定結果を送信
    alt 新しい設備や現象と判定
        Func->>MASTv2: 新規マスタ候補として登録 即時承認フローも設定可能
    end

    alt 過去の要確認データを開いた場合
        User->>App: 類似案件検索から対象データを選択
        App->>OUT: 既存データを取得
        App-->>User: 要確認フラグを表示し補足を促す
        User->>App: 補足情報を入力
        App->>Func: 補足内容と元データを送信
        Func->>LLM: 整合性確認とマッピングを実施
        LLM-->>Func: 更新案を返却
        Func->>OUT: 保全DBを更新し要確認フラグを解除
    end

    App->>OUT: 新規または更新の保全データを保存
```

---
