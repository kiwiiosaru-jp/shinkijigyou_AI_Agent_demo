# 保全業務DXおよび既存データ資産化プロジェクト 提案書

---

## 目次

1. タイトル  
2. 本日のアジェンダ  
3. プロジェクト背景（弊社理解）  
4. ご提案サマリ（3つの柱）  
5. 現状の課題：負の連鎖（Vicious Cycle）  
6. 技術アプローチの全体像（LLM主導：3フロー構成）  
7. 提案要旨①の詳細：AIクレンジング＆マスタ自動生成  
8. アルゴリズム詳細①：ラインマスタ（文字列距離＋LLM）  
9. アルゴリズム詳細②：設備・部品マスタ（LLM＋Embedding＋Pythonクラスタリング）  
10. アルゴリズム詳細③：分類マスタ・標準用語辞書  
11. 提案要旨②の詳細：RAG検索＆AI入力支援アプリ（Power Automate中心）  
12. 提案要旨③の詳細：  
    「少し試す → 確かめる → 全体に広げる」と  
    マスタ／保全データを“育てる”運用  
13. 「育てる」① 初期構築でマスタを育てる（10％ → 90％）  
14. 「育てる」② 運用しながらマスタを育てる  
15. 「育てる」③ 運用しながら保全報告データを育てる  
16. システムアーキテクチャ（バッチ基盤と運用基盤の分離）  
17. Power Platform ライセンス選択ガイド  
18. プロジェクトロードマップ（3ヶ月）  
19. 概算費用とROI（投資対効果）  
20. 将来の発展イメージ（本スコープ外：予防保全）  
21. 次のアクション（Next Steps）  
22. 体制とDATUM STUDIOの強み  

---

# 1. タイトル

**タイトル**  
保全業務DXおよび既存データ資産化プロジェクトのご提案  

**サブタイトル**  
Power Platform × Generative AI (GPT-5) による「ナレッジ駆動型保全」への変革  

**宛名**  
いすゞ自動車株式会社 御中  

**日付**  
2026年1月  

**提案者**  
DATUM STUDIO  

---

# 2. 本日のアジェンダ

1. プロジェクト背景とご提案サマリ  
2. 現状の課題：「負の連鎖」と23万件データの状態  
3. 技術アプローチの全体像（LLM主導：3フロー構成）  
4. 提案要旨①：AIクレンジング＆マスタ自動生成の詳細  
5. 提案要旨②：RAG検索＆AI入力支援アプリの詳細  
6. 提案要旨③：「少し試す → 確かめる → 全体に広げる」と“育てる”運用  
7. システムアーキテクチャ  
8. ライセンス・ロードマップ・概算費用とROI  
9. 将来の発展イメージ（予防保全）  
10. 次のアクション／体制  

---

# 3. プロジェクト背景（弊社理解）

## 3-1. ヘッダーメッセージ

> 「23万件の埋蔵データの資産化」と「現場入力業務の高度化」の課題に対し、  
> Azure OpenAI × Power Platform による保全ナレッジDX基盤の構築を提案する。  
> 生成AIによるデータクレンジングの自動化と、検索・入力支援アプリの実装により、  
> 現場の負荷を増やさずに高品質な保全データを継続的に蓄積できる仕組みを実現する。

## 3-2. 現状の理解

- 既存の**保全履歴23万件**は、すでにCSVおよびDBとして構造化されている。  
- しかし、以下のような**品質課題**が存在している。  
  - 表記揺れ（例：モータ／モーター／Mtr）  
  - 略語・誤字・俗語  
  - 項目のズレ（原因欄に処置内容が入っている 等）  
- このため、現状のままでは**検索や分析に耐えない**状態となっている。  
- 全件を人手で修正した場合、  
  - 23万件 × 5分/件 = 約19,000時間  
  - 現場のリソースでは事実上対応不可能な規模である。  

---

# 4. ご提案サマリ（3つの柱）

## 4-1. 提案要旨①  
### AIクレンジング＆マスタ自動生成による「23万件の一括資産化」

- GPT-5を用いた構造化・補正エンジンと、Python（Scikit-learn）によるクラスタリング・名寄せロジックを組み合わせる。  
- 既存23万件の保全データから、  
  - ラインマスタ  
  - 設備・部品マスタ  
  - 現象・原因・処置マスタ  
  - 標準用語辞書（略語・表記揺れ → 正式名称）  
  を自動生成し、これを用いて全件をクレンジングする。  
- 約19,000時間相当の人手作業をAIで代替し、データを「資産」として再利用可能な状態にする。  

**位置づけ：**  
蓄積済みの23万件を一気に整える、**「過去（Stock）の資産化」**の施策。

## 4-2. 提案要旨②  
### RAG検索＆AI入力支援アプリによる「勝手に整うデータ運用」

- Power Apps上に、Azure OpenAIと連携した保全アプリを構築する。  
- 現場担当者は「日本語で素直に入力」するだけで、  
  - 過去の類似事例の提示（RAG検索）  
  - 標準用語への変換サジェスト  
  - 現象／原因／処置などへの自動振り分け  
  - 不足情報の指摘・質問  
  が自動的に行われる。  
- 結果として、**「現場が楽になればなるほど、データが勝手に整っていく」**運用サイクルを実現する。  

**位置づけ：**  
日々の入力・検索の負荷を下げながら、良質なデータを継続的に生む、**「今後の運用（Flow）の効率化」**の施策。

## 4-3. 提案要旨③  
### 「少し試す → 確かめる → 全体に広げる」と  
### マスタ／保全データを少しずつ“育てる”運用設計

- いきなり全自動ではなく、以下の3段階で進める構成とする。  
  1. **少し試す**：データの約10％を用いて、AIがマスタのたたき台を自動生成。  
  2. **確かめる**：たたき台だけ人が確認・修正し、初期マスタとして確定。  
  3. **全体に広げる**：残り90％をクレンジングしながら、未知の設備・事象をマスタに追加。  
- 運用フェーズでは、  
  - 新しい設備や現象が出てきた際のマスタへの追加  
  - 類似案件検索のタイミングでの“ついで補正”  
  を通じて、**マスタと保全報告データの双方を運用の中で継続的に育てる**。

**位置づけ：**  
データとマスタを少しずつ磨き上げることで、将来的な予防保全や高度分析にもつながる**「Future」への橋渡し**となる運用設計。

---

# 5. 現状の課題：負の連鎖（Vicious Cycle）

## 5-1. 顧客のペイン

> 「データを使って業務を効率化したいが、検索しても過去の類似事象がヒットしない。  
>  結果として入力の手間も減らず、ナレッジも活用できない。」

## 5-2. 負の連鎖のメカニズム

1. 過去データに表記揺れ・項目ズレ・欠損が多く、検索してもヒットしない。  
2. データ整備には約19,000時間が必要であり、現場では工数を確保できない。  
3. 整備が後回しになる中、日々の業務で新たな揺らぎデータが蓄積し続ける。  
4. 時間が経つほど「データ量は増えるが、活用は難しくなる」状況に陥っている。  

## 5-3. 「約19,000時間の壁」

- 23万件 × 5分/件 ≒ 約19,000時間という、人手では現実的に超えられない工数が「壁」となり、データ活用を阻んでいる。  
- この壁を、人を増やすのではなく、AIという仮想労働力で乗り越えることが本プロジェクトのポイントである。  

## 5-4. 解決の方向性

- 足りていないのは「やる気」ではなく「工数」である。  
- 必要な約19,000時間分を、GPT-5という**仮想労働力**によって肩代わりすることで、負の連鎖と「約19,000時間の壁」を同時に突破する。  

---

# 6. 技術アプローチの全体像（LLM主導：3フロー構成）

## 6-1. 全体構成

本提案における処理フローは、次の3つの層で構成される。

1. **バッチ1：マスタ初期生成バッチ（10％サンプル）**  
2. **バッチ2：初期データクレンジングバッチ（23万件全件）**  
3. **運用フロー：AI入力補助付き保全データ登録（オンライン）**  

これらを、**2つの技術基盤**に分けて実装します。

- **データ整備バッチ基盤（Backend for Setup）**  
  - Azure Functions (Python) 上で動作。  
  - Scikit-learn によるクラスタリング（DBSCAN/KMeans等）、  
    Levenshtein距離計算、Pandasによる集計など、  
    計算量の大きい処理を一括実行する役割。  

- **運用アプリケーション基盤（Runtime）**  
  - Power Apps ＋ Power Automate を中心に構成。  
  - Power Automate から直接  
    - Azure OpenAI（HTTPコネクタ）  
    - Azure AI Search（コネクタ）  
    を呼び出し、**Pythonランタイムを運用時には使わない**構成とする。  

## 6-2. 処理フローのイメージ（テキスト図）

```text
[既存保全DB (23万件)]
        |
        | ① 10% サンプル抽出
        v
[バッチ1：マスタ初期生成 (Azure Functions / Python + Scikit-learn)]
        |
        v
[初期マスタ + 標準用語辞書]
        |
        | ② 全件クレンジング
        v
[バッチ2：クレンジングバッチ (Azure Functions / Python)]
        |
        +--> [クレンジング済DB (Dataverse)]
        |
        +--> [要確認フラグ付きデータ]
        |
        +--> [マスタ追加候補リスト]

日々の運用:
  現場作業員
        |
        v
  [保全アプリ (Power Apps)]
        |
        v
  [Power Automate]
        |
        +--> Azure OpenAI (構造化・補正・サジェスト)
        +--> Azure AI Search (RAG検索)
        +--> Dataverse (保全DB/マスタ/辞書の更新)
```

## 6-3. この構成によるメリット

- **コスト最適化**  
  - 重いPython処理（クラスタリングなど）は、初期構築や再学習時の**バッチ**に限定。  
  - 日常運用では Power Platform + Azure OpenAI / AI Search の従量課金のみで動作し、  
    常時稼働のFunctionsやPython環境の運用コストを抑制できる。  

- **保守性・内製化のしやすさ**  
  - 現場での仕様変更・画面改修は、主に Power Apps / Power Automate のローコード開発で完結。  
  - Pythonコードに触るのは「マスタ生成ロジックの見直し」など限定的な場面に絞られるため、  
    内製チームでもキャッチアップしやすい。  

- **処理性能の確保**  
  - 23万件のクラスタリング・名寄せ等は、  
    Azure Functions 上で Scikit-learn や各種数値計算ライブラリをフル活用することで、  
    精度と速度のバランスを確保できる。  

---
