# 電力需要予測 × LLM フル比較 Notebook 基本設計書（v2.2）
（日本向け公開・AIレディ合成データ検証用 / Chronos-bolt FT対応版）

---

## 0. 目的・仮説・成功基準（公共データ前提）

### 0.1 目的（Public Mission）
本Notebookの目的は、日本向け電力需要データ（**実データ＋合成データ**）について、  
**「ベースモデルの思想差」と「LLMによる知的補正の効果」**を包括的に検証し、AIレディな公開データ基盤として妥当であることを実証することである。

特に合成データを、単なる学習量増強（Augmentation）としてだけでなく、**RAG（検索拡張生成）のナレッジベース**として活用し、過去の「特異なシナリオ」をLLMが参照することで、**特異点日における予測精度が向上するか**を明らかにする。

> **重要**：LLMに需要そのもの（絶対値）を予測させない。  
> LLMは **「補正（adjustment）」** と **「説明（explanation）」** を担う。

---

### 0.2 仮説（Hypotheses）

#### H1（データ中立性：Augmentation & RAG）
合成データは特定のモデル思想（統計 / GBDT / DL / Foundation）に偏った利益を与えず、公平な改善効果を提供する。

- **H1a（Aug check）**：Realのみ学習 vs Real+Syn学習において、モデルごとの改善幅に極端な偏りがない。

#### H2（知能価値：特異点補正）
猛暑・寒波・イベント等の特異点日において、数値予測のみのベースモデルよりも、合成データ由来のシナリオ知識（定性情報）を参照した **LLM補正あり** の方が有意に高精度となる。

#### H3（補正の分化：弱点補完）
LLMの補正効果は、ベースモデルの弱点（反応遅れ / 過学習傾向 など）を補完する形で現れる。  
この「弱点」は **Validation残差統計からデータ駆動で定義**する。

---

### 0.3 成功基準（Notebookで自動判定）

#### 精度要件
- 特異点日における **LLM補正あり** の平均改善率 ≥ **3%**（**2モデル以上**で成立）
- 特異点日改善率の **ブートストラップ95%信頼区間** の下限 > **0%**（改善が偶然でない）
- 全期間の平均悪化率 ≤ **+0.5%**（副作用の抑制）

#### 運用要件
- LLM起動率 ≤ **10%**（コスト制御）
- **空振り率**：起動したのに改善≤0 だった割合を表示（目安 ≤ **50%**）

#### 公平性要件（H1の判定）
- Augmentationによる改善幅（ΔMAE%）の **モデル間レンジ ≤ 2pt**
- RAGによる改善幅の **モデル間レンジ ≤ 2pt**

---

## 1. 実験フェーズとモデル設計

### 1.1 実験フェーズ構成（H1aの分離）
H1a（Augmentationの中立性）と H2（LLMの効果）を混同しないよう、2段階で検証する。

**Phase 1：Augmentation 効果検証（H1a）**
- 各モデルに対し、「実データのみ学習（Real）」vs「合成データ込み学習（Real+Syn）」を比較する。
- Chronos-bolt などの Fine-tuning における学習データソース差（Real / Real+Syn）を確認する。

**Phase 2：RAG/LLM 補正効果検証（H2, H3）**
- Phase 1 の Realモデル（または Real+Synモデル）をベースとして、推論時に RAG/LLM を適用して効果を測定する。
- 本Notebookの主眼は Phase 2 にあるため、比較マトリクスは Phase 2 を中心に設計する。

---

### 1.2 ベースモデル群（思想別）

| 区分 | モデル | 役割 | 設定方針 |
|---|---|---|---|
| 古典統計 | SARIMAX | 統計的下限・解釈性 | 外生変数あり、最小構成 |
| GBDT | LightGBM | 実務代表 | ラグ特徴量＋カレンダー、Optuna等で調整 |
| 時系列DL | PatchTST | 深層学習代表 | Transformerベース、長短期依存 |
| Foundation | Chronos-bolt | 性能上限代表 | Fine-tuning実施（少量データ適応検証） |

---

### 1.3 フル比較マトリクス（寄与分解込み）
LLM（言語能力）と RAG（類似検索ルール）の寄与を切り分ける Ablation Study。

> ※ ベースモデルは原則「Phase 1で構築したモデル（学習済み）」を使用。

| ID | Baseモデル | RAG | LLM補正 | 目的（評価観点） |
|---|---|---:|---:|---|
| A1 | SARIMAX | なし | なし | 統計ベースライン |
| A2 | SARIMAX | あり | あり | 統計の硬直性 × 知識補正 |
| A3 | SARIMAX | あり | なし | RAGのみ寄与（ルールベース補正） |
| A4 | SARIMAX | なし | あり | LLMのみ寄与（知識なし・幻覚チェック） |
| B1〜B4 | LightGBM | 同上 | 同上 | 実務ベース比較 |
| C1〜C4 | PatchTST | 同上 | 同上 | DLベース比較 |
| D1〜D4 | Chronos-bolt(FT) | 同上 | 同上 | FMベース比較 |

---

## 2. データ設計（実データ＋合成データ）

### 2.1 実データ（公開電力需要）
- 構造：`timestamp, demand_actual, temp_forecast, temp_actual(分析用), calendar_features...`
- **Test期間は実データのみ**を使用し、汚染を完全に防止する。
- 注意：入力には原則 **予報気温** を使用。実測気温は「事後分析・上限性能確認」用とする。

---

### 2.2 合成データ（公共財・ナレッジベース用）

#### 2.2.1 生成ロジック（中立性担保）
予測モデル（DL/GBDT）とは異なる発想（例：エージェントシミュレーション、構造方程式など）で生成し、特定のモデル構造に有利なバイアスを排除する。

#### 2.2.2 データ構造と「基準化」（RAG精度向上の肝）
合成データは「絶対値」ではなく「相対的な特異度」としてLLMに渡すため、**基準化指標**を持たせる。

- 数値データ：`timestamp, demand_syn, temp, humidity...`
- **基準化指標（Model-Agnostic）**
  - `seasonal_baseline`：**カレンダー区分別**の移動中央値  
    - 区分：平日 / 土曜 / 日祝  
    - 計算：直近 `N_weeks` 週間の **同区分・同時間帯** の中央値（祝日汚染を回避）
  - `anomaly_multiplier = demand_syn / seasonal_baseline`  
    - 例：「過去のこのケースはベースライン比 1.05倍だった」
- テキストメタデータ
  - `scenario_reason`：例「猛暑による冷房需要急増に加え、大型連休初日が重なり上振れ」
  - `scenario_tags`：例 `["heatwave", "holiday_transition", "demand_surge"]`

#### 2.2.3 構成比率
- 合成データ総数：`N_syn`
- うち、特異点シナリオ（Knowledge用）を **30%程度**含める。

---

## 3. データ分割とリーク対策

### 3.1 分割
- Train（70%）：ベースモデル学習用（Phase 1）
- Validation（15%）：ハイパーパラメータ調整、および補正係数 **α, β** の決定
- Test（15%）：**実データのみ**。最終評価用

### 3.2 予測時点の情報の厳格化（Leakage Guardrails）
特異点検知・RAG検索において、当日 `t` の需要実績は使用禁止。

- 使用可能情報
  - `t-1` までの実績
  - 当日 `t` の確定情報（予報気温、カレンダー、既知イベント）

---

## 4. 特異点検知（起動用）と特異点分類（評価用）

### 4.1 LLM起動用ゲート（オンライン想定）
LLMコスト抑制のため、以下の **OR条件** で起動する。閾値は **Trainデータのみで決定し固定**する。

- **予報気温外れ値**：Train期間の `p99` 超過 or `p01` 未満
- **イベント発生**：祝日・特定イベントフラグ ON
- **直近トレンド異常**：`t-24`〜`t-1` の実測値と単純移動平均の乖離が閾値超過

### 4.2 評価用の特異点カテゴリ（分析軸）
結果分析のため、特異点を事後的にカテゴリ分類する（例）。

- `heat_extreme`（猛暑）
- `cold_extreme`（寒波）
- `holiday_transition`（連休）
- `trend_shift`（急変）

---

## 5. RAG 設計（検索拡張生成）

### 5.1 検索クエリ
- 数値：予報気温、湿度、曜日、時刻、直近需要トレンド統計
- テキスト：簡易状況要約（例：「猛暑予報、連休初日」）

### 5.2 検索ロジック（Vector Search + MMR）
- Vector Search：クエリに近い上位 `N` 件を取得
- MMR（Maximal Marginal Relevance）：
  - 「クエリに近い」かつ「候補同士が似すぎていない（多様性）」を満たす **3件** を抽出

> 目的：同じ猛暑日でも「平日」「休日」「節電時」など多様なパターンの挙動をLLMに提示する。

---

## 6. LLM 補正推論フロー（Phase 2）

### 6.1 入力プロンプト構成（構造化）
LLMには **計算をさせず、判断のみ** を行わせる。

- 役割定義（Persona）
  - 「あなたは電力需要予測の補正専門家です。現在のベースモデルは [モデル名] です。」
- モデル特性（Validation残差からのデータ駆動注入）
  - **重要：主観ではなくデータに基づく癖**を教える  
  - 例：「このモデルは休日明けに平均 +1.5% の過大予測をする傾向があります。」
- 当日条件：日時、予報気温、イベントなど
- 参考知識（RAG Context 3件）
  - 各事例の `scenario_reason` と `anomaly_multiplier`（対ベースライン比率）を提示
- 禁止事項（計算ミス防止）
  - 「最終予測値（kW）の計算は行わないでください。」

---

### 6.2 出力フォーマット（JSON）
```json
{
  "adjustment_rate": 0.03,
  "confidence": 0.85,
  "decision": "apply",
  "reasoning": "RAG事例ではベースライン比 +5% の上振れが見られるが、使用モデルは休日明けを過大評価する癖があるため、補正は控えめな +3% 程度が妥当と判断。",
  "rag_ids": ["syn_102", "syn_077"]
}
```

---

### 6.3 安全装置と予測値確定
Python側で計算する。

\[
\hat{y}_{final}=\hat{y}_{base}\times(1+\alpha \times adjustment\_rate)
\]

- **α（信頼係数）**：Validationで最適化（モデルごとに設定）  
  - LLMが過信気味なら \(\alpha < 1.0\) で抑制
- Fail-safe：JSONパース失敗時は補正なし（0.0）

---

## 7. RAGのみ補正（LLMなし）ルール（A3/B3/C3/D3用）
LLMの言語能力が不要かを検証するための対照実験。

- 検索された3件の `anomaly_multiplier` の中央値を `m` とする

\[
\hat{y}_{rag}=\hat{y}_{base}\times(1+\beta \times (m-1))
\]

- **β**：Validationで最適化した係数  
- これにより「類似データの数値を平均するだけで十分か（LLM不要説）」を検証する

---

## 8. 評価指標と可視化

### 8.1 定量評価
- 精度：MAE, RMSE, MAPE（全体 vs 特異点カテゴリ別）
- 改善率：Baseモデルに対する誤差削減率（ブートストラップ信頼区間を付与）
- コスト効率：（改善MAE総量）/（消費トークン推計額）
- 公平性（H1）：
  - AugmentationおよびRAGによる改善率のモデル間分散（レンジや分散を報告）

### 8.2 可視化（Notebook Output）
- 時系列プロット：実績、Base、補正後（特異点日をハイライト）
- 散布図：横軸=Base誤差、縦軸=補正量  
  - 正の相関があれば「間違いを正しく直している」
- ヒートマップ：行=モデル、列=カテゴリ（猛暑/寒波/イベント）、値=改善率
- 運用ダッシュボード：起動率、空振り率、トークンコスト

---

## 9. 結論の導出（公共財としての検証）
Notebookの実行結果に基づき、以下のステートメントを出力する。

### 9.1 合成データの妥当性（H1）
- Augmentation（Phase 1）と RAG（Phase 2）の両面で、特定のモデルに偏らない利益を提供できたか？

### 9.2 LLMの知能価値（H2）
- 「RAGのみ（ルールベース）」と比較して、「LLMあり」が有意に勝ったか？
- 勝った場合、LLMは文脈（メタデータ）を正しく解釈できたと言えるか？

### 9.3 実務的推奨
- 「Chronos-bolt（FT）」単体か、「LightGBM + LLM」か  
- **コスト対効果**を含めた最適なアーキテクチャを提案する

---

## 付録：再現性・公開品質チェック
- seed固定、ライブラリバージョン明記
- 中間データ（Validation残差統計、最適化された **α, β**）の保存
- LLMプロンプトテンプレートの公開
