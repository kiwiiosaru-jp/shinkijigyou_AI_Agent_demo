# 提案書骨子：AI駆動型データカタログ＆リネージ基盤構築

提案書の骨子としてそのまま活用できるよう、**「課題仮説 vs 価値提案」の形式でストーリーを整理し、その後に「機能比較付きWBS」**を配置しました。  
Snowflake と Databricks は、どちらも「生成AI」と「メタデータ管理」に猛烈に投資していますが、そのアプローチ（SQL中心か、コード中心か）に明確な違いがあります。

---

## 1. 課題仮説と提供価値（Value Proposition）

お客様の現状（As-Is）から想定される「真の課題」と、本プロジェクトが実現する「あるべき姿（To-Be）」および当社が提供する価値を定義します。

| 領域 | お客様の課題・問題の仮説（As-Is Issues） | 当社の価値提案（Value Proposition） |
|---|---|---|
| 全体 | **「データのブラックボックス化」と「信頼の欠如」**<br>基盤は速いが、中身（ロジック・意味）が属人化しており、誰も全貌を把握できていない。結果、データ活用が進まない。 | **「ホワイトボックス化」と「Traceability（追跡可能性）」**<br>AIを用いてブラックボックスを開け、誰もがデータの「素性（出自・意味）」を確認できる透明性の高い基盤を提供する。 |
| パイプライン | **「秘伝のタレ化したPython/独自ツール」**<br>・コードを書いた担当者しか修正できない。<br>・障害時に「どこで何が止まったか」の調査に数日かかる。<br>・リファクタリングが進まず、技術的負債が増え続ける。 | **「AIによる自動カタログ化と自律運用」**<br>・既存コードをAIが解析し、「日本語の仕様書（カタログ）」を自動生成。<br>・AIがエラーログを読み解き、原因と修正案を即座に提示するAIOps環境を実現。 |
| データベース | **「高速なゴミ捨て場 (Vertica)」**<br>・性能は高いが、テーブル定義書が古く、カラム名（col_01等）から意味が推測できない。<br>・「似たようなテーブル」が乱立し、どれが正（Official）か不明。 | **「意味（Semantics）と品質が定義された資産管理」**<br>・物理テーブルに**「ビジネス用語」と「品質ランク」**を付与。<br>・Verticaからの移行と同時に、AIでメタデータを整備し、「探せる・信頼できる」状態へ昇華させる。 |
| アプリ/BI | **「一方通行のダッシュボード」**<br>・数字に違和感があっても、確認手段がない（情シスへ問い合わせるしかない）。<br>・「なぜこの数字？」という疑問が解決せず、意思決定に使われない。 | **「対話型のデータ素性提供（Data Lineage）」**<br>・BI画面にAIエージェントを配備。<br>・「このデータのソースは？計算式は？」という問いに、カタログとリネージを即座に参照して回答し、データの信頼性を担保する。 |

---

## 2. 開発WBSとツール機能対応一覧

Snowflake と Databricks が、各タスクをどうカバーできるかを明記しました。  
※ **「◎」は標準機能で強みあり、「○」は可能、「△」は工夫や外部ツールが必要**。

---

### Phase 1：データパイプライン層（処理のカタログ化とAI自動化）

| WBS ID | タスク名 | Snowflake での実現手段 | Databricks での実現手段 |
|---|---|---|---|
| 1.1 | 現行コードの<br>AI解析・可視化 | ○ Snowflake Cortex (LLM)<br>・PythonコードをテキストとしてCortexに投げ、「要約・解説」させることは可能。<br>・外部ツールのリネージ自動取得機能はないため、テキストベースの解析が主。 | ◎ Databricks Assistant / Unity Catalog<br>・ノートブック内のコード解析が得意。<br>・Unity Catalogはコード内の入出力を解析し、リネージ（依存関係）を自動描画する能力が非常に高い。 |
| 1.2 | パイプライン<br>カタログ設計 | △ 外部ツール推奨<br>・タスク管理機能はあるが、「カタログ」としての視認性は低い。<br>・dbt Cloud等と組み合わせるのが一般的。 | ◎ Workflows / Unity Catalog<br>・ジョブ自体をUnity Catalogで管理可能。<br>・各タスクにタグや説明を付与し、カタログの一部として管理できる。 |
| 1.3 | AIリファクタリング<br>自動化検証 | ○ Dynamic Tables<br>・「宣言的」にSQLを書けば、パイプライン構築・更新を自動化できる（簡易化）。<br>・Cortexで既存コードをSQLに変換可能。 | ◎ Delta Live Tables (DLT)<br>・Python/SQLで記述し、品質チェック（Expectations）も含めてパイプラインを自動生成。<br>・Assistant機能でレガシーコードの移植支援が強力。 |
| 1.4 | 自動化運用<br>プロセス設計 | ○ Alerts & Notifications<br>・エラー時のメール通知等は可能。<br>・高度な自動復旧は外部オーケストレータが必要な場合が多い。 | ○ Workflows / Lakehouse Monitoring<br>・ジョブ失敗時の自動リトライ、条件分岐が柔軟。<br>・モニタリング機能でエラー傾向を可視化可能。 |

---

### Phase 2：データベース基盤層（データ資産のカタログ整理）

| WBS ID | タスク名 | Snowflake での実現手段 | Databricks での実現手段 |
|---|---|---|---|
| 2.1 | カタログメタデータ<br>整備構想 | ◎ Snowflake Horizon<br>・ガバナンス機能の総称。「Object Tagging」や「Universal Search」で強力な検索性を提供。<br>・Cortexを活用してコメント（説明文）を自動生成可能。 | ◎ Unity Catalog<br>・業界最高水準の統合カタログ。<br>・**「AI-Generated Comments」**機能が標準実装されており、カラムの意味をAIが勝手に記述してくれる。 |
| 2.2 | Vertica移行と<br>カタログ連携 | ◎ Snowpipe / COPY INTO<br>・データロードが極めて簡単。<br>・外部カタログ（Alation等）との連携コネクタが充実している。 | ○ Auto Loader / Federation<br>・Lakehouse Federationを使えば、移行過渡期にVerticaを直接参照（仮想統合）しつつカタログ管理できる。 |
| 2.3 | データ品質<br>(Quality) 定義 | ○ Data Metric Functions<br>・システム定義のメトリクス（NULL数など）を測定可能。<br>・ダッシュボード化はSnowsightで行う。 | ◎ Lakehouse Monitoring<br>・プロファイル画面が自動生成され、品質推移（鮮度、分布の変化）をGUIでグラフィカルに確認できる点が優位。 |
| 2.4 | アクセス権限と<br>ガバナンス | ◎ Dynamic Masking / RBAC<br>・SQLベースできめ細やかな行・列レベルの制御が可能。<br>・管理が直感的で、DBAに好まれる。 | ◎ Unity Catalog Access Control<br>・SQLおよびPython、ファイルレベルで統一的な権限管理が可能。<br>・属性ベースのアクセス制御（ABAC）も強力。 |

---

### Phase 3：アプリケーション層（BI ＋ データ素性提供窓口）

| WBS ID | タスク名 | Snowflake での実現手段 | Databricks での実現手段 |
|---|---|---|---|
| 3.1 | 「データ素性」<br>UX設計 | ◎ Streamlit in Snowflake<br>・Pythonのみでチャット画面やデータ確認アプリを爆速開発。<br>・基盤の中にアプリがあるため、セキュリティ的に最強。 | ○ Databricks Apps<br>・Streamlit等をホストする機能が登場。<br>・まだ新しいため、エコシステムの成熟度はSnowflakeが先行。 |
| 3.2 | RAG基盤設計<br>(知識ベース) | ◎ Cortex Search / Cortex Analyst<br>・**「Cortex Analyst」**が本命。構造化データ（テーブル）に対して自然言語でクエリする専用API。<br>・カタログ情報を読ませて回答させる精度が高い。 | ◎ Mosaic AI / Genie<br>・**「Genie」**というデータ分析特化のAIエージェント機能あり。<br>・RAGの構築（Vector Search）から評価までフルスタックで提供。 |
| 3.3 | プロトタイプ検証<br>(AI窓口) | ○ Snowflake Notebooks<br>・ノートブック上でCortexを呼び出し、Streamlitで即UI化して検証するサイクルが速い。 | ◎ AI Playground / Genie Space<br>・チャットUI（Playground）が用意されており、プロンプトエンジニアリングの試行錯誤が容易。 |
| 3.4 | 利用ガイドライン<br>策定 | △ ドキュメントベース<br>・ツールの機能というより、運用ルールの策定が主。 | △ ドキュメントベース<br>・同左。 |

---

## 3. 推奨アーキテクチャの方向性（提案の締めくくり）

上記の比較から、お客様の現在の志向性に合わせて以下の2パターンのいずれかを提案します。

### パターンA：SQL & 管理性重視なら「Snowflake」

**なぜ**：Verticaからの移行において、SQLの親和性が高く、移行リスクが低い。  
また、**「Streamlit」**によるAIアプリ開発の手軽さが、エンドユーザー向けの「データ素性窓口」作成に最適であるため。

- **キーワード**：Snowflake Horizon（ガバナンス）、Cortex Analyst（対話型AI）、Streamlit（アプリ化）

### パターンB：Python & 自律運用重視なら「Databricks」

**なぜ**：既存のPython/独自ツールによる複雑なパイプラインを、Unity Catalogで可視化・管理する能力が圧倒的。  
Lakehouse Monitoring による「品質の可視化」が標準機能だけでリッチに実現できるため。

- **キーワード**：Unity Catalog（リネージ・カタログ）、Databricks Assistant（コード解析）、Lakehouse Monitoring（品質監視）

---

この構成案であれば、単なる機能比較にならず、  
**「お客様の『不透明なデータ環境』という課題を、どの機能で『透明化』するか」**というストーリーで提案が可能です。
